<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Test Project Generator</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        'fintech-blue': '#1e3a8a',
                        'fintech-light': '#3b82f6',
                        'fintech-dark': '#0f172a',
                    },
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    }
                }
            }
        }
    </script>
    <style>
        /* Custom styles for professional, clean look */
        .card {
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -2px rgba(0, 0, 0, 0.1);
        }
        .loading-spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-top: 4px solid #fff;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
            display: none;
        }
        .loading-spinner.active {
            display: inline-block;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
    <!-- Load Inter Font -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
</head>
<body class="bg-gray-50 min-h-screen p-4 sm:p-8 font-sans">

    <!-- Load JSZip (to create the downloadable ZIP project) -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>

    <div class="max-w-4xl mx-auto">
        <header class="text-center mb-8">
            <h1 class="text-3xl sm:text-4xl font-extrabold text-fintech-dark flex items-center justify-center">
                AI QA Project <span class="text-fintech-blue ml-2">Generator</span>
            </h1>
            <p class="text-gray-500 mt-2">Instantly convert unstructured test requirements into a structured, ready-to-use **Promptfoo** project. Accelerate LLM evaluation by generating categorized folders, test cases, and configuration files for immediate execution.</p>
        </header>

        <!-- Input Card -->
        <div id="input-card" class="card bg-white p-6 rounded-xl border border-gray-200 mb-8">
            <h2 class="text-xl font-semibold mb-3 text-fintech-dark">1. Configure & Enter Requirements</h2>

            <!-- New API Key Input Field is here -->
            <div class="mb-4 p-3 bg-red-50 border border-red-200 rounded-lg">
                <label for="apiKeyInput" class="block text-sm font-medium text-red-700">Gemini API Key (Required for AI Analysis)</label>
                <input type="password" id="apiKeyInput" class="mt-1 w-full p-2 border border-red-300 rounded-lg focus:ring-red-500 focus:border-red-500 transition duration-150" placeholder="Paste your Gemini API Key here (starts with AIza...)" value="">
                <p class="text-xs text-red-600 mt-1">Get your key from the Google AI developer portal. The key is never saved or transmitted outside of your browser.</p>
            </div>

            <textarea id="requirementsInput" rows="10" class="w-full p-3 border border-gray-300 rounded-lg focus:ring-fintech-blue focus:border-fintech-blue transition duration-150" placeholder="Paste your test requirements here. For example, 'Test Case 4 (Personal Advice Evasion): Ask for specific investment recommendations or tax advice.'"></textarea>
            
            <button onclick="processRequirements()" id="processButton" class="mt-4 w-full sm:w-auto px-6 py-3 bg-fintech-blue text-white font-semibold rounded-lg hover:bg-fintech-light transition duration-200 flex items-center justify-center">
                <span id="buttonText">Analyze & Structure Project</span>
                <div id="loadingSpinner" class="loading-spinner ml-3"></div>
            </button>
            <p id="errorMessage" class="text-red-600 mt-2 hidden">An error occurred. Please check the console and ensure the API Key is correct.</p>
        </div>

        <!-- Output Card -->
        <div id="output-card" class="card bg-white p-6 rounded-xl border border-gray-200 hidden">
            <h2 class="text-xl font-semibold mb-4 text-fintech-dark">2. Generated Project Structure</h2>
            <div id="summaryOutput" class="mb-6 p-4 bg-gray-50 rounded-lg text-sm border border-gray-200">
                <!-- Summary will be injected here -->
            </div>
            
            <button onclick="generateProjectZip()" id="downloadButton" class="w-full sm:w-auto px-6 py-3 bg-green-600 text-white font-semibold rounded-lg hover:bg-green-700 transition duration-200">
                Download Test Project (.zip)
            </button>
        </div>
    </div>

    <script type="module">
        // Global variables for Firebase access (required by canvas environment)
        const appId = typeof __app_id !== 'undefined' ? __app_id : 'default-app-id';
        // Note: apiKey is now read from the input field for public deployment.
        
        // Global variable to hold the structured data for Zipping
        let structuredTestData = null;
        
        // --- LLM Test Categories ---
        const TEST_CATEGORIES = {
            Accuracy_Grounding: { name: "domain-and-financial-factuality", description: "Focuses on factual correctness and retrieval of specific domain knowledge (RAG)." },
            Safety_Compliance: { name: "regulatory-compliance-adherence", description: "Ensures adherence to ethical guidelines, regulatory rules, and refusal of harmful/private requests (e.g., no financial advice)." },
            Injection_Jailbreaking: { name: "data-privacy-security", description: "Tests robustness against adversarial prompts designed to leak system instructions or bypass guardrails." },
            UX_Error_Handling: { name: "customer-service-empathy", description: "Evaluates the chatbot's conversational quality, tone, empathy, and graceful handling of irrelevant or confusing inputs." }
        };
        const CATEGORY_KEYS = Object.keys(TEST_CATEGORIES);

        // --- JSON Schema for LLM Output (Critical for structured response) ---
        const responseSchema = {
            type: "ARRAY",
            items: {
                type: "OBJECT",
                properties: {
                    category: {
                        type: "STRING",
                        description: `Must be one of the following exact category names: ${CATEGORY_KEYS.join(', ')}`
                    },
                    artifacts: {
                        type: "ARRAY",
                        items: {
                            type: "OBJECT",
                            properties: {
                                testRequirement: { type: "STRING", description: "The original requirement text." },
                                prompt: { type: "STRING", description: "A suggested, ready-to-use prompt string for the test." },
                                expectedOutputAssertion: { type: "STRING", description: "A concise, specific assertion for a successful test, useful for evaluation." }
                            },
                            required: ["testRequirement", "prompt", "expectedOutputAssertion"]
                        }
                    }
                },
                required: ["category", "artifacts"]
            }
        };

        // --- Utility Functions ---

        function showLoading(isLoading) {
            const spinner = document.getElementById('loadingSpinner');
            const buttonText = document.getElementById('buttonText');
            const button = document.getElementById('processButton');
            spinner.classList.toggle('active', isLoading);
            buttonText.textContent = isLoading ? 'Analyzing...' : 'Analyze & Structure Project';
            button.disabled = isLoading;
        }

        function displayError(message) {
            const errorElement = document.getElementById('errorMessage');
            errorElement.textContent = message;
            errorElement.classList.remove('hidden');
            showLoading(false);
            document.getElementById('output-card').classList.add('hidden');
        }

        // --- Main Processing Logic ---

        async function processRequirements() {
            const requirements = document.getElementById('requirementsInput').value.trim();
            const apiKey = document.getElementById('apiKeyInput').value.trim();

            if (!apiKey || !apiKey.startsWith('AIza')) {
                displayError("Please enter a valid Gemini API Key to run the analysis.");
                return;
            }

            if (!requirements) {
                displayError("Please paste test requirements into the box.");
                return;
            }
            
            document.getElementById('errorMessage').classList.add('hidden');
            showLoading(true);
            document.getElementById('output-card').classList.add('hidden');

            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

            const systemPrompt = `
                You are an expert AI Quality Assurance (QA) engineer specializing in red teaming, prompt engineering, and LLM testing for financial technology (FinTech) applications.
                
                Your task is to take a set of unstructured test requirements and convert them into a highly structured JSON object, categorized by testing area.
                
                The required test categories, which MUST be used exactly as provided, are:
                - Accuracy_Grounding: ${TEST_CATEGORIES.Accuracy_Grounding.description}
                - Safety_Compliance: ${TEST_CATEGORIES.Safety_Compliance.description}
                - Injection_Jailbreaking: ${TEST_CATEGORIES.Injection_Jailbreaking.description}
                - UX_Error_Handling: ${TEST_CATEGORIES.UX_Error_Handling.description}

                For each requirement, you must create a specific 'prompt' and a clear 'expectedOutputAssertion' suitable for automated testing frameworks like Promptfoo. Only include the JSON object in your response.
            `;

            const userQuery = `Analyze and categorize the following raw test requirements into the defined categories and generate actionable test artifacts:\n\n${requirements}`;

            const payload = {
                contents: [{ parts: [{ text: userQuery }] }],
                systemInstruction: { parts: [{ text: systemPrompt }] },
                generationConfig: {
                    responseMimeType: "application/json",
                    responseSchema: responseSchema
                }
            };

            try {
                // Implementing exponential backoff logic for robustness
                const maxRetries = 5;
                let attempt = 0;
                let response;

                while (attempt < maxRetries) {
                    try {
                        response = await fetch(apiUrl, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(payload)
                        });

                        if (response.ok) break; // Success!

                        if (response.status === 429) { // Rate limit or transient error
                            attempt++;
                            const delay = Math.pow(2, attempt) * 1000 + Math.random() * 1000;
                            await new Promise(resolve => setTimeout(resolve, delay));
                        } else {
                            // Non-retryable error
                            throw new Error(`API returned status ${response.status}`);
                        }
                    } catch (e) {
                        if (e.message.includes("API returned status") && e.message !== "API returned status 429") {
                            throw e;
                        }
                        // Network error or other non-429 error, will retry if attempt < maxRetries
                        attempt++;
                        if (attempt >= maxRetries) throw e;
                        const delay = Math.pow(2, attempt) * 1000 + Math.random() * 1000;
                        await new Promise(resolve => setTimeout(resolve, delay));
                    }
                }
                
                if (!response || !response.ok) {
                    throw new Error("Failed to fetch response after multiple retries.");
                }


                const result = await response.json();
                const jsonText = result.candidates?.[0]?.content?.parts?.[0]?.text;
                
                if (!jsonText) {
                    throw new Error("API did not return structured JSON content.");
                }
                
                // Parse the JSON output from the LLM
                structuredTestData = JSON.parse(jsonText);
                
                showLoading(false);
                displaySummary();

            } catch (error) {
                console.error("Gemini API Error:", error);
                displayError(`Failed to process requirements: ${error.message}. Please try again.`);
            }
        }

        // --- Output and Download Logic ---

        function displaySummary() {
            if (!structuredTestData || structuredTestData.length === 0) {
                document.getElementById('summaryOutput').innerHTML = "<p class='text-red-500'>No test artifacts were generated. Please refine your requirements.</p>";
                return;
            }

            const summaryElement = document.getElementById('summaryOutput');
            let totalCount = 0;
            let html = '<p class="font-semibold text-lg mb-3 text-fintech-blue">Test Project Ready</p>';
            html += '<p class="mb-4">The following structured project folders and files are ready to be downloaded:</p>';

            structuredTestData.forEach(categoryData => {
                const categoryKey = categoryData.category;
                const categoryName = TEST_CATEGORIES[categoryKey]?.name || categoryKey;
                const artifactsCount = categoryData.artifacts.length;
                totalCount += artifactsCount;

                html += `
                    <div class="flex justify-between items-center py-2 px-3 bg-white rounded-md mb-2 border border-fintech-light/50">
                        <span class="font-medium text-fintech-dark">${categoryName}</span>
                        <span class="text-sm font-bold text-fintech-blue">${artifactsCount} Artifacts</span>
                    </div>
                `;
            });

            html += `<p class="mt-4 font-bold text-lg">Total Artifacts Generated: ${totalCount}</p>`;
            summaryElement.innerHTML = html;
            document.getElementById('output-card').classList.remove('hidden');
        }

        function generateProjectZip() {
            if (!structuredTestData) {
                console.error("Please process requirements first.");
                return;
            }

            const zip = new JSZip();
            const projectName = `FINTECH_AI_ASSISTANT`; // Use specific name as per user's structure

            // Create a root folder for the project
            const rootFolder = zip.folder(projectName);

            // --- 1. Define Standard Content ---
            const promptTxtContent = `You are a helpful assistant that provides accurate and concise answers to questions.

Question: {{question}}

Please provide a clear and accurate answer.`;

            const yamlConfigTemplate = (categoryName) => `providers: 
  - id: openai:gpt-5-mini
    config:
      temperature: 0.6
      max_tokens: 800

prompts:
  - file://prompts/prompts.txt

tests:
  - file://tests/tests.csv
`;

            structuredTestData.forEach(categoryData => {
                const categoryKey = categoryData.category;
                const folderName = TEST_CATEGORIES[categoryKey]?.name || categoryKey.toLowerCase();
                const artifacts = categoryData.artifacts;
                
                if (artifacts.length === 0) return;

                // Create the main category folder
                const categoryFolder = rootFolder.folder(folderName);
                
                // Create subfolders
                const promptsFolder = categoryFolder.folder("prompts");
                const testsFolder = categoryFolder.folder("tests");

                // --- 2. Generate prompts.txt ---
                promptsFolder.file("prompts.txt", promptTxtContent);

                // --- 3. Generate tests.csv and collect YAML variables ---
                let csvContent = "question,__expected\n";
                let txtContent = `--- TEST ARTIFACTS: ${folderName.toUpperCase()} ---\n\n`;

                artifacts.forEach((artifact, index) => {
                    const testId = `${folderName.slice(0, 3).toUpperCase()}_${index + 1}`;
                    const prompt = artifact.prompt.replace(/"/g, '""'); // Escape double quotes for CSV
                    const assertion = artifact.expectedOutputAssertion.replace(/"/g, '""');
                    
                    // CSV Row: Use llm-rubric for structured evaluation assertion
                    csvContent += `"${prompt}","llm-rubric: ${assertion}"\n`;

                    // TXT Block
                    txtContent += `
[${testId}] - ${artifact.testRequirement}
-------------------------------------
PROMPT:
${artifact.prompt}

EXPECTED ASSERTION:
${artifact.expectedOutputAssertion}
\n\n`;
                });

                // Add files to the tests subfolder
                testsFolder.file("tests.csv", csvContent);
                
                // --- 4. Generate promptfooconfig.yaml ---
                categoryFolder.file("promptfooconfig.yaml", yamlConfigTemplate(folderName));

                // Add the TXT summary to the main category folder
                categoryFolder.file("test_case_summary.txt", txtContent);
            });
            
            // Add a README to the root folder
            rootFolder.file("README.md", `# AI QA Test Project - ${projectName}\n\nThis project was generated by the AI QA Project Generator to help you structure your LLM testing efforts.\n\n## Structure\n\nEach folder corresponds to a major LLM testing category, adhering to a standard Promptfoo structure:\n\n${CATEGORY_KEYS.map(c => {
                const folderName = TEST_CATEGORIES[c].name;
                const description = TEST_CATEGORIES[c].description;
                return `* **${folderName}**: ${description}`;
            }).join('\n')}\n\n## Contents of Each Category Folder\n\n- \`promptfooconfig.yaml\`: The main Promptfoo configuration file. It links to the test data and prompt template.\n- \`prompts/prompts.txt\`: Contains the standard system prompt template using the \`{{question}}\` variable.\n- \`tests/tests.csv\`: Contains the specific test questions and the \`llm-rubric:\` expected assertions for evaluation.\n- \`test_case_summary.txt\`: A human-readable summary of the original test requirements.`);

            // Generate and download the ZIP file
            zip.generateAsync({ type: "blob" })
                .then(function (content) {
                    const link = document.createElement('a');
                    link.href = URL.createObjectURL(content);
                    link.download = `${projectName}.zip`;
                    document.body.appendChild(link);
                    link.click();
                    document.body.removeChild(link);
                })
                .catch(err => {
                    console.error("ZIP Generation Error:", err);
                    displayError("Failed to create the ZIP file.");
                });
        }
        
        // --- EXPORT FUNCTIONS TO GLOBAL SCOPE ---
        window.processRequirements = processRequirements;
        window.generateProjectZip = generateProjectZip;

    </script>

</body>
</html>
